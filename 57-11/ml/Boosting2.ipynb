{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "rR28CrOF7X2j"
      },
      "source": [
        "# Практическое задание 6: Градиентный бустинг"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGuTHcED7i4j"
      },
      "source": [
        "## Подготовка рабочей среды\n",
        "Сначала установим нужные нам версии библиотек.\n",
        "\n",
        "После установки нужных версий, **возможно,** нужно перезагрузить среду (runtime), но скорее всего вам это не понадобится"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gSWrzAD7iIq"
      },
      "outputs": [],
      "source": [
        "!pip install gdown numpy pandas scikit-learn xgboost catboost lightgbm hyperopt matplotlib seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpN7nlaE7X2q"
      },
      "source": [
        "## Используемые библиотеки\n",
        "\n",
        "В этом задании могут понадобится четыре библиотеки (помимо sklearn), а именно:\n",
        "\n",
        "**XGBoost**: Документация [здесь](https://xgboost.readthedocs.io/en/stable/).<br />\n",
        "**LightGBM**: Документация [здесь](https://lightgbm.readthedocs.io/en/latest/index.html). Также дополнительно про установку [тут](https://pypi.org/project/lightgbm/).<br />\n",
        "**Catboost**: Документация [здесь](https://catboost.ai/en/docs/). Можно найти также некоторую информацию на русском [тут](https://habr.com/ru/company/otus/blog/527554/).<br />\n",
        "**HyperOpt**: Документация [здесь](http://hyperopt.github.io/hyperopt/). <br />\n",
        "\n",
        "<font color='red'>**Внимание!**</font> Вникать и подробно читать документацию к каждой библиотеке нет необходимости! Достаточно обращаться туда для нахождения примеров.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyx8TlnM7X2q"
      },
      "source": [
        "## Напоминание, как правильно перебирать параметры\n",
        "\n",
        "\n",
        "1. <font color='green'>**learning_rate**</font> $-$ **темп обучения** нашего метода. Для этого метода сетка перебора должна быть логарифмической, т.е. перебирать порядковые значения (к примеру, `[1e-3, 1e-2, 1e-1, 1]`). В большинстве случаев достаточно перебрать значения от `1e-5 до 1`.<br />\n",
        "\n",
        "2. <font color='green'>**max_depth**</font> $-$ **максимальная глубина деревьев** в ансамбле. Вообще говоря, эта величина зависит от числа признаков, но обычно лучше растить небольшие деревья. К примеру, библиотека `CatBoost`, которую мы будем исследовать сегодня, рекомендует перебирать значения до `10` (и уточняется, что обычно оптимальная глубина лежит `от 6 до 10`).<br />\n",
        "\n",
        "3. <font color='green'>**subsample**</font> $-$ **объем выборки**, использующийся для обучения отдельного дерева, лежит в интервале `(0, 1]`. Перебирать стоит хотя бы с шагом `0.25` <br />\n",
        "\n",
        "4. <font color='green'>**n_estimators**</font> $-$ **количество деревьев** в ансамбле. Обычно стоит перебирать с каким-то `крупным шагом` (можно по логарифмической сетке). Здесь важно найти баланс между производительностью, временем обучения и качеством. Обычно `нескольких тысяч` деревьев бывает достаточно.<br />\n",
        "\n",
        "<font color='red'>**NB!**</font> Учтите, что в реальных задачах необходимо следить за тем, что оптимальные значения параметров не попадают на границы интервалов, т.е. что вы нашли хотя бы локальный минимум. Если вы перебрали значения параметра от 1 до 10 и оказалось, что 10 $-$ оптимальное значение, значит следует перебрать и бОльшие числа, чтобы убедиться, что качество не улучшается дальше (или по крайней мере убедиться, что рост качества сильно замедляется и на сильное улучшение рассчитывать не стоит.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "PQYs352Y7X21"
      },
      "source": [
        "### HyperOpt\n",
        "\n",
        "Обычнно перебор параметров и поиск по сетке это самая скучная часть работы, поскольку занимает много времени, но не гарантирует воспроизведение результата при небольшом изменении датасета, да и сетку надо переосмысливать при каждом обновлении.\n",
        "\n",
        "Но этого можно избежать, поскольку есть библиотека, которая всё сделает за нас! Нашего спасителя зовут `HyperOpt`. На первый взгляд hyperopt делает всё то же самое, что и grid search, а именно перебирает параметры. По факту же hyperopt превращает это в задачу оптимизации, используя некоторые эвристики для ускорения сходимости процесса. К тому же, он требует лишь информацию о границе интервалов, а не сами сетки. В теории это должно помочь нам добиться лучших результатов за более короткое время. \n",
        "\n",
        "Примерный порядок действий:\n",
        "1. Взять `любую библиотеку градиентного бустинга`.\n",
        "2. Составить `сетку перебора в hyperopt`, включающую параметры n_estimators, max_depth, subsample и learning_rate в hyperopt. Вам могут понадобиться такие типы данных, как `hp.choice, hp.qloguniform, hp.uniform и hp.quniform`(можно также пользоваться np.arange). Также для округления значения типа float до целых чисел (4.0 $\\to$ 4) можно использовать `scope.int`.\n",
        "3. `Реализовать функцию`, которая принимает на вход словарь параметров для регрессора, и при помощи CV оценивает его качество на датасете (можно воспользоваться cross_val_score, а для ускорения поставить cv=3). \n",
        "4. Создать объект `trials=Trials()`, который будет хранить информацию о процессе оптимизации. Используя функцию fmin, можно `оптимизировать функцию`. Можно установить algo=tpe.suggest, trials=trials и max_evals, по крайней мере, 50. verbose=1 позволит видеть прогресс-бар по типу tqdm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ro50Y3f17X21"
      },
      "source": [
        "# Предсказание зрительских симпатий\n",
        "\n",
        "----------------------------------------------\n",
        "<font color=\"white\" style=\"opacity:0.2023\"></font>\n",
        "\n",
        "В некотором царстве, некотором государстве была развита кинопромышленность. Новые фильмы в этом государстве показывают по интернету, а пользователи после просмотра могут дать фильму некоторую \"награду\". Наша цель $-$ предсказать число наград для фильма."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Описание данных\n",
        "\n",
        "В нашем распоряжении имеются следующие данные:\n",
        "\n",
        "- **awards** $-$ количество наград, полученных фильмом от пользователей (целевое значение)  \n",
        "- **potions** $-$ количество магических зелий, потраченных на создание спец-эффектов  \n",
        "- **genres** $-$ жанры созданного фильма  \n",
        "- **questions** $-$ количество вопросов, заданных пользователями на соответствующих форумах об этом фильме до премьеры  \n",
        "- **directors** $-$ режиссеры фильма (если неизвестны, то `unknown`)  \n",
        "- **filming_locations** $-$ области, в которых снимался фильм  \n",
        "- **runtime** $-$ продолжительность фильма в некоторых единицах, принятых в этом государстве  \n",
        "- **critics_liked** $-$ количество критиков из 100, присудивших награды фильму на предварительных закрытых показах  \n",
        "- **pre-orders** $-$ количество зрителей, заранее купивших билеты на первый показ  \n",
        "- **keywords** $-$ ключевые слова, описывающие содержание фильма\n",
        "- **release_year** $-$ год, во котором фильм был показан (конечно, в летоисчислении этого государства)\n",
        "\n",
        "Следующие поля появляются несколько раз с разными значениями `i`:\n",
        "\n",
        "- **actor_i_known_movies** $-$ количество известных фильмов актера `i` (i от 0 до 2)\n",
        "- **actor_i_postogramm** $-$ количество подписчиков в социальной сети \"по сто грамм\" актера `i` (i от 0 до 2)\n",
        "- **actor_i_gender** $-$ пол актера `i` (i от 0 до 2)\n",
        "- **actor_i_age** $-$ возраст актера `i` (i от 0 до 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Формат данных\n",
        "\n",
        "Данные разбиты на три части: тренировочная часть, публичные тестовые команды (которые вы можете скачать) и приватные тестовые файлы. \n",
        "\n",
        "Данные хранятся в виде JSONL-файлов, то есть файлов, в которых каждая строка $-$ это JSON. Каждая строка соответствует одному объекту в датасете. Ключи этого JSON соответствуют названиям переменных. В примере решения Вы можете увидеть как читать такие файлы без проблем.\n",
        "\n",
        "**Важно!** В тестовом файле сохраняйте даннные в том же порядке, в котором они записаны в файл!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "Вот по [этой ссылке](https://drive.google.com/file/d/1wCOyYTt-n1UU1Snf5O4ExVUuvkhkI3y_/view?usp=sharing) хранится ZIP-архив с публичными данными и шаблоном решения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# при работе в Colab'е можно использовать эту ячейку для скачивания\n",
        "!gdown 1wCOyYTt-n1UU1Snf5O4ExVUuvkhkI3y_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Устройство архива\n",
        "\n",
        "```\n",
        "solution_template/\n",
        "│\n",
        "├── run.py\n",
        "│   → Основной скрипт запуска решения. \n",
        "│\n",
        "├── awards_prediction.py\n",
        "│   → Модуль с логикой предсказаний (обучение модели, обработка данных,\n",
        "│     применение ML-алгоритма и т.п.). Может содержать класс или функции для\n",
        "│     подготовки данных и построения прогноза.\n",
        "│\n",
        "└── public_tests/\n",
        "    ├── 01_boosting_movies_gt/\n",
        "    │   └── target.json\n",
        "    │       → Файл с эталонными значениями для публичного теста.\n",
        "    │\n",
        "    └── 01_boosting_movies_input/\n",
        "        ├── test/\n",
        "        │   └── test.jsonl\n",
        "        │       → Публичный тестовый набор данных в формате JSON Lines.\n",
        "        │\n",
        "        └── train/\n",
        "            └── train.jsonl\n",
        "                → Публичный обучающий набор данных в формате JSON Lines.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Решение\n",
        "**<font color='red'>Внимание!</font>** Подбирать оптимальные параметры стоит **только** на локальном компьютере / в Google Colab!\n",
        "В решении Вы должны использовать регрессор с оптимальными параметрами, которые вы нашли путём перебора по сетке.\n",
        "\n",
        "В шаблонном файле `awards_prediction.py` Вы должны реализовать функцию `train_model_and_predict`, которая получает на вход папку для обучения и теста. На обучении вы обучаете ваш алгоритм, а затем возвращаете предсказания значений `awards` для всех фильмов из теста. Предсказания должны быть расположены в том же порядке, в котором они находятся в тесте (то есть, не примените где-то случайно `shuffle`).\n",
        "\n",
        "В этом файле вы можете создавать любые дополнительные функции и методы, которые нужны вам для решения. Главное – сохранить интерфейс функции `train_model_and_predict`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Советы по решению\n",
        "В этом задании Вы можете добиться лучшего качества при помощи:\n",
        "- Предобработки датасета, выбора категориальных переменных и дополнительной фильтрации.\n",
        "- Выбора лучшего метода обучения и подбора оптимальных параметров с использованием кросс-валидации.\n",
        "\n",
        "**<font color='red'>Внимание!</font>** Учтите, что при OHE кодировании признаки на обучении и тестировании должны совпадать! Если вы примените простое `.get_dummies()` или что-то подобное, то признаки на трейне и тесте получатся разные! Так что вам, вероятно, придётся придумать способ для того, чтобы сохранить их :)  \n",
        "\n",
        "**<font color='red'>Внимание!</font>** Нельзя исключать вероятность того, что злые силы добавили в наш датасет пропуски, поэтому лучше лишний раз как-нибудь заполнить пропущенные значения.\n",
        "\n",
        "**Подсказка**: для работы с текстом можно воспользоваться методом TF-IDF (ключевые слова: TfIdfTransformer). Также может быть полезен CountVectorizer. Только учтите, что никто не гарантирует улучшение результата с использованием данных методов  ;)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Разрешенные методы и библиотеки\n",
        "В качестве метода обучения предлагается использовать **любой регрессор**, основанный на градиентном бустинге деревьев. Разрешается пользоваться библиотеками sklearn, xgboost, lightgbm, catboost.\n",
        "\n",
        "**Жесткого требования использовать градиентный бустинг нет!** Градиентный бустинг является одним из лучших методов обучения на сегодняшний день, поэтому будет даже интересно, удастся ли кому-то получить макс. балл альтернативными методами.\n",
        "\n",
        "Также разрешается пользоваться библиотекой hyperopt для подбора параметров модели (параметры стоит подбирать локально, а в систему загружать решение с подобранными параметрами)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Оценивание\n",
        "\n",
        "В качестве метрики качества используется значение MAE.\n",
        "\n",
        "Баллы выставляются по следующим правилам:\n",
        "- 9 баллов: $\\text{MAE} ∈ [0, 2050]$,\n",
        "- 7 баллов: $\\text{MAE} ∈ (2050, 2100]$,\n",
        "- 5 баллов: $\\text{MAE} ∈ (2100, 2150]$,\n",
        "- 3 баллов: $\\text{MAE} ∈ (2150, 2200]$,\n",
        "- 1 балла: $\\text{MAE} ∈ (2200, 2300]$,\n",
        "- 0 баллов: $\\text{MAE} ∈ (2300, +∞]$\n",
        "\n",
        "Значение MAE будет посчитано раздельно на публичной и приватной выборках. Количество полученных баллов на приватной выборке будет дополнительно умножено на 2. Таким образом за это задание Вы можете получить до 27 баллов (9 на публичной и 18 на приватной выборках)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Тестирование\n",
        "Скачайте ZIP-архив c шаблоном решения и разархивируйте его. Далее следуйте инструкциям по запуску тестирования.\n",
        "\n",
        "Тесты запускаются внутри папки с шаблоном через терминал с помощью команды:\n",
        "```bash\n",
        "python run.py\n",
        "```\n",
        "\n",
        "Учтите, что после запуска скрипта будет создано несколько дополнительных файлов и директорий (это\n",
        "связано с работой тестирующей системы).\n",
        "\n",
        "Если всё верно, то Вы увидите что-то вроде `Mark: 1 OK, mae = [2287.341688095019]`, т.е. Вашу оценку и значение MAE на публичном датасете."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQiS55pdmnS-"
      },
      "source": [
        "## **<font color='orange'>Задание (27 баллов)</font>**\n",
        "**Данные**: датасет с наградами за фильмы\n",
        "\n",
        "**Метрика**: MAE  \n",
        "\n",
        "**Цели**: В данном задании следует выполнить следующие пункты:  \n",
        "1. Взять `любую библиотеку`.\n",
        "2. Используя предложенный датасет, `обучить регрессор` для предсказания awards (предоставляем полную свободу в настройках и выборе методов).\n",
        "3. Получить качество больше порогового значения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fr_YAXOF7X22"
      },
      "outputs": [],
      "source": [
        "## your efficient code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
